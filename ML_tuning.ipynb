{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8226e55-724c-4403-b8a2-febed74bc158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "px.defaults.width = 1200\n",
    "px.defaults.height = 800\n",
    "# plotly.io Settings for both plotly.graph_objects and plotly.express\n",
    "pio.templates.default = \"plotly_white\" # \"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"\n",
    "pio.kaleido.scope.default_format = 'svg'\n",
    "pio.kaleido.scope.default_scale = 1\n",
    "\n",
    "# Data Preprocessing - Standardization, Encoding, Imputation\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.preprocessing import Normalizer # Normalization\n",
    "from sklearn.preprocessing import OneHotEncoder # One-hot Encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "from category_encoders import MEstimateEncoder # Target Encoding\n",
    "from sklearn.preprocessing import PolynomialFeatures # Create Polynomial Features\n",
    "from sklearn.impute import SimpleImputer # Imputation\n",
    "\n",
    "# Exploratory Data Analysis - Feature Engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling - ML Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Modeling - Algorithms\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# ML - Evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ML - Tuning\n",
    "import optuna\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Settings\n",
    "# Settings for Seaborn\n",
    "sns.set_theme(context='notebook', style='ticks', palette=\"bwr_r\", font_scale=0.7, rc={\"figure.dpi\":240, 'savefig.dpi':240})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239dbdee-e119-4525-8838-b783c46549a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/201601/reviews.csv\n",
      "./data/201601/listings_kfold.csv\n",
      "./data/201601/listings.csv\n",
      "./data/201601/calendar.csv\n",
      "./data/201601/.ipynb_checkpoints/listings_kfold-checkpoint.csv\n",
      "./data/201601/.ipynb_checkpoints/calendar-checkpoint.csv\n",
      "./data/201601/.ipynb_checkpoints/listings-checkpoint.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "kaggle_project = 'settle-airbnb'\n",
    "# Import dataset from local directory './data' or from Kaggle\n",
    "data_dir = ('./data/201601' if os.path.exists('data') else f'/kaggle/input/{kaggle_project}')\n",
    "\n",
    "# print all files in data_dir\n",
    "for dirname, _, filenames in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Import three datasets\n",
    "reviews = pd.read_csv(f'{data_dir}/reviews.csv')\n",
    "calendar = pd.read_csv(f'{data_dir}/calendar.csv')\n",
    "listings = pd.read_csv(f'{data_dir}/listings_kfold.csv') if os.path.exists(f'{data_dir}/listings_kfold.csv') else pd.read_csv(f'{data_dir}/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc24bdf-dc4c-45f0-a572-2b575f82f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL_pipeline:\n",
    "    def __init__(self, data_frame):\n",
    "        self.df = data_frame\n",
    "    \n",
    "    # Data type transformation\n",
    "    def _transformation(self, data_frame):\n",
    "        df = data_frame\n",
    "        # Convert dollar columns from object to float\n",
    "        # Remove '$' and ','\n",
    "        dollar_cols = ['price', 'weekly_price', 'monthly_price', 'extra_people', 'security_deposit', 'cleaning_fee']\n",
    "        for dollar_col in dollar_cols:\n",
    "            df[dollar_col] = df[dollar_col].replace('[\\$,]', '', regex=True).astype(float)\n",
    "        # Convert dollar columns from object to float\n",
    "        # Remove '%'\n",
    "        percent_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "        for percent_col in percent_cols:\n",
    "            df[percent_col] = df[percent_col].replace('%', '', regex=True).astype(float)\n",
    "\n",
    "        # Replace the following values in property_type to Unique space due to small sample size\n",
    "        unique_space = [\"Barn\",\n",
    "        \"Boat\",\n",
    "        \"Bus\",\n",
    "        \"Camper/RV\",\n",
    "        \"Treehouse\",\n",
    "        \"Campsite\",\n",
    "        \"Castle\",\n",
    "        \"Cave\",\n",
    "        \"Dome House\",\n",
    "        \"Earth house\",\n",
    "        \"Farm stay\",\n",
    "        \"Holiday park\",\n",
    "        \"Houseboat\",\n",
    "        \"Hut\",\n",
    "        \"Igloo\",\n",
    "        \"Island\",\n",
    "        \"Lighthouse\",\n",
    "        \"Plane\",\n",
    "        \"Ranch\",\n",
    "        \"Religious building\",\n",
    "        \"Shepherdâ€™s hut\",\n",
    "        \"Shipping container\",\n",
    "        \"Tent\",\n",
    "        \"Tiny house\",\n",
    "        \"Tipi\",\n",
    "        \"Tower\",\n",
    "        \"Train\",\n",
    "        \"Windmill\",\n",
    "        \"Yurt\",\n",
    "        \"Riad\",\n",
    "        \"Pension\",\n",
    "        \"Dorm\",\n",
    "        \"Chalet\"]            \n",
    "        df.property_type = df.property_type.replace(unique_space, \"Unique space\", regex=True)\n",
    "\n",
    "        # Convert 't', 'f' to 1, 0\n",
    "        tf_cols = ['host_is_superhost', 'instant_bookable', 'require_guest_profile_picture', 'require_guest_phone_verification']\n",
    "        for tf_col in tf_cols:\n",
    "            df[tf_col] = df[tf_col].replace('f', 0, regex=True)\n",
    "            df[tf_col] = df[tf_col].replace('t', 1, regex=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Parse listings\n",
    "    def parse_listings(self):\n",
    "        df = self.df\n",
    "        df = self._transformation(df)\n",
    "        return df\n",
    "    \n",
    "    def parse_reviews(self):\n",
    "        df = self.df\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "        return df\n",
    "    \n",
    "    # Parse calendar\n",
    "    def parse_calender(self):\n",
    "        df = self.df\n",
    "        # Convert date from object to datetime\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "        # Convert price from object to float\n",
    "        # Convert '$' and ',' to ''\n",
    "        df.price = df.price.replace('[\\$,]', '', regex=True).astype(float)\n",
    "        \n",
    "        # Convert 't', 'f' to 1, 0\n",
    "        df['available'] = df['available'].replace('f', 0, regex=True)\n",
    "        df['available'] = df['available'].replace('t', 1, regex=True)\n",
    "        \n",
    "        calendar.available\n",
    "        #\n",
    "        # Imputation\n",
    "        #\n",
    "        # Imputation -> Forward filling\n",
    "        #calendar['price_ffill'] = calendar.groupby('listing_id')['price'].transform(lambda col: col.ffill())\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adc9395-b94c-4130-900e-d60073c5605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = ETL_pipeline(listings).parse_listings()\n",
    "reviews = ETL_pipeline(reviews).parse_reviews()\n",
    "calendar = ETL_pipeline(calendar).parse_calender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab4dec7-d07e-4e63-9fe0-96aa30327ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDA:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def reviews_rate_vs_unavailability(self, period=30):\n",
    "        \"\"\"Calculate the booked listing from file calendar.\n",
    "\n",
    "        Args:\n",
    "            period (int): Positive integer. Default is 30.\n",
    "\n",
    "        Returns:\n",
    "            Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        assert (0 < period <= 365) & isinstance(period, int), \"period must be an integer and greater than 0\"\n",
    "        self.period = period\n",
    "        \n",
    "        #\n",
    "        # Calculate review rate & unavailability\n",
    "        #\n",
    "\n",
    "        # reviews Rate: review / days\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            listing_id, \n",
    "            COUNT(listing_id) / DATEDIFF(20160104+1, MIN(date)) AS reviews_per_day\n",
    "        FROM reviews\n",
    "        GROUP BY listing_id\n",
    "        \"\"\"\n",
    "        # Extract the first reviews date for each listing\n",
    "        func = lambda df: pd.Series({'first_day': df.date.min()})\n",
    "        df_reviews_per_day = pd.DataFrame(reviews.groupby('listing_id').apply(func))\n",
    "        # Define last scraped date\n",
    "        last_scraped = listings.last_scraped.unique()[0]\n",
    "        last_scraped = pd.Timestamp(last_scraped)\n",
    "        df_reviews_per_day['last_day'] = last_scraped + pd.DateOffset(days=1)\n",
    "        # Calculate the datediff\n",
    "        df_reviews_per_day['datediff'] = df_reviews_per_day.last_day - df_reviews_per_day.first_day\n",
    "        df_reviews_per_day['datediff'] = df_reviews_per_day['datediff'].dt.days\n",
    "        # Calculate the reviews Rate\n",
    "        df_reviews_per_day['reviews_per_day'] = reviews.groupby('listing_id').size() / df_reviews_per_day['datediff']\n",
    "\n",
    "        \"\"\"\n",
    "        SELECT listing_id, SUM(IF(available = 0, 1, 0))\n",
    "        FROM calendar\n",
    "        WHERE DATEDIFF(date, 20160104) <= period\n",
    "        GROUP BY listing_id\n",
    "        \"\"\"\n",
    "        last_day = last_scraped + pd.DateOffset(days=period-1)\n",
    "        filter = calendar.date <= (last_day)\n",
    "        func = lambda df: pd.Series({f'unavailability_{period}_unscaled': sum(df.available == 0)}) # Scaling available to day scale\n",
    "        df_unavailability = pd.DataFrame(calendar[filter].groupby('listing_id').apply(func))\n",
    "        df_unavailability[f'unavailability_{period}'] = df_unavailability[f'unavailability_{period}_unscaled'] / period\n",
    "        #df_unavailability['first_day'] = last_scraped\n",
    "        #df_unavailability['last_day'] = last_day\n",
    "        self.df_unavailability = df_unavailability\n",
    "        \n",
    "        # Join two tables\n",
    "        df_unavailability_reviews = df_unavailability.join(df_reviews_per_day, how='left')\n",
    "        df_unavailability_reviews.reviews_per_day.fillna(value=0, inplace=True)\n",
    "        #df_unavailability_reviews.loc[:, [f'unavailability_{period}_unscaled', f'unavailability_{period}', 'reviews_per_day']]\n",
    "        \n",
    "        # Find outliers (unavailable rather than booked)\n",
    "        # Extrat quantiles\n",
    "        reviews_rate_25 = df_unavailability_reviews.reviews_per_day.quantile(q=0.25, interpolation='higher')\n",
    "        unavailability_75 = df_unavailability_reviews[f'unavailability_{period}'].quantile(q=0.75, interpolation='higher')\n",
    "        # Low reviews rate: 0.010376\n",
    "        filter1 = df_unavailability_reviews.reviews_per_day < reviews_rate_25\n",
    "        # High unavailability: 0.660274\n",
    "        filter2 = df_unavailability_reviews[f'unavailability_{period}'] > unavailability_75\n",
    "\n",
    "        outliers = df_unavailability_reviews[filter1 & filter2]\n",
    "        df_unavailability_reviews['demand'] = df_unavailability_reviews[f'unavailability_{period}_unscaled']\n",
    "        df_unavailability_reviews.loc[outliers.index, 'demand'] = period - df_unavailability_reviews.loc[outliers.index, 'demand']\n",
    "        \n",
    "        self.outliers = outliers\n",
    "        self.df_unavailability_reviews = df_unavailability_reviews\n",
    "        \n",
    "        return self.df_unavailability_reviews\n",
    "    \n",
    "    def plot(self, outliers=True):\n",
    "        \"\"\"Display plot or describe the relationship between reviews per day and unavailabilities to filter the outliers of demand.\n",
    "        \n",
    "        Args:\n",
    "            outlier (bool): Display outliers or not. Default is True\n",
    "            \n",
    "        Returns:\n",
    "            Plotly instance\n",
    "        \"\"\"\n",
    "        period = self.period\n",
    "        \n",
    "        if outliers is True:\n",
    "            idx = self.outliers.index\n",
    "            df = self.df_unavailability_reviews.loc[idx, :]\n",
    "        else:\n",
    "            idx = self.df_unavailability_reviews.index.drop(self.outliers.index)\n",
    "            df = self.df_unavailability_reviews.loc[idx, :]\n",
    "\n",
    "        assert df.shape[0] > 0, \"No records\"\n",
    "\n",
    "        fig = px.line(df, \n",
    "                      x=df.index, \n",
    "                      y=[f'unavailability_{period}', 'reviews_per_day'],\n",
    "                      color_discrete_sequence=['rgb(71, 92, 118, 0.9)', 'rgb(250, 211, 102, 0.9)']\n",
    "                     )\n",
    "        fig.update_layout(title=f'Unavailability per day vs. reviews per day<br>Outliers', xaxis_title='index', yaxis_title='Rate')\n",
    "\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659ded14-058a-4fc8-932a-03236bfbe505",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Official Features\n",
    "How many people are searching for listings like yours\n",
    "The dates theyâ€™re looking at\n",
    "Whether other listings are getting booked\n",
    "Your listingâ€™s best qualities\n",
    "Your neiborhood: To calculate pricing based on location, Smart Pricing looks at whether your listing is in a city neighborhood, a suburb, or a more spread-out area.\n",
    "Review rate: The number and quality of your reviews is another key factor in Smart Pricing.\n",
    "Completed trips: If you honor most confirmed reservations, your prices can go higher within the minimum and maximum range you set.\n",
    "Your listing' amenities: Wi-fi, washer/dryer, and air conditioning are especially important, but Smart Pricing looks at all your amenities.\n",
    "'''\n",
    "\n",
    "class ML_pipeline:\n",
    "    \"\"\"ML Pipeline for listings.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_frame, features, target, days=365):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            data_frame (Pandas DataFrame): listings.\n",
    "            features (list): The Machine Learning features.\n",
    "            target (str): price\n",
    "            days (int): The days after 2016-01-04 for calculating demand.\n",
    "        \"\"\"\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\") # ignore target encoding warnings\n",
    "        \n",
    "        # Get demand\n",
    "        demand = EDA().reviews_rate_vs_unavailability(days)\n",
    "        # The index will change to id\n",
    "        data_frame = data_frame.set_index('id').join(demand['demand'], how='inner')\n",
    "        \n",
    "        features.append(target)\n",
    "        data_frame = data_frame[features]\n",
    "        \n",
    "        # Encode amenities\n",
    "        data_frame = self._encode_amentities(data_frame)\n",
    "        data_frame.pop('amenities')\n",
    "        \n",
    "        self.data_frame = data_frame\n",
    "        \n",
    "    # encode amentities\n",
    "    def _encode_amentities(self, data_frame):\n",
    "        # Replace amenities from {}\" to ''\n",
    "        data_frame.amenities.replace('[{}\"]', '', regex=True, inplace=True)\n",
    "        # Split amenities with ,\n",
    "        amenities = data_frame.amenities.str.split(',', expand=True)\n",
    "\n",
    "        # For each col, extract the unique amenities\n",
    "        amenities_uniques = []\n",
    "        for col in amenities.columns:\n",
    "            amenities_uniques += list(amenities[col].unique())\n",
    "\n",
    "        # Remove the duplicate values\n",
    "        amenities_uniques = set(amenities_uniques)\n",
    "        amenities_uniques.remove('')\n",
    "        amenities_uniques.remove(None)\n",
    "        # Only two rows have Washer / Dryer, and they both have washer and dryer\n",
    "        amenities_uniques.remove('Washer / Dryer')\n",
    "        # When 'Pets live on this property' is True, one or more from 'Cat(s)', 'Dog(s)', 'Other pet(s)' will appear\n",
    "\n",
    "        # Encoding amenities\n",
    "        amenities_enc = pd.DataFrame()\n",
    "        for amenity in amenities_uniques:\n",
    "            amenities_enc[amenity] = data_frame.amenities.str.contains(amenity, regex=False)\n",
    "\n",
    "        # Rename the columns with prefix amenity_\n",
    "        amenities_enc.columns = [f\"amenity_{col}\" for col in amenities_enc.columns]\n",
    "        \n",
    "        # Concat encoded amenities and data_frame\n",
    "        data_frame = pd.concat([data_frame, amenities_enc], axis=1)\n",
    "\n",
    "        return data_frame\n",
    "\n",
    "    def _imputation(self, X_train, X_valid, y_train, y_valid):\n",
    "        X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "        \n",
    "        # Zero imputation\n",
    "        # Reason:\n",
    "        zero_imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "        zero_features = ['reviews_per_month', 'host_response_rate', 'host_is_superhost', 'security_deposit', 'cleaning_fee']\n",
    "        X_train_zero_imp = pd.DataFrame(zero_imp.fit_transform(X_train[zero_features]))\n",
    "        X_valid_zero_imp = pd.DataFrame(zero_imp.transform(X_valid[zero_features]))\n",
    "        X_train_zero_imp.columns = zero_features\n",
    "        X_valid_zero_imp.columns = zero_features\n",
    "        X_train_zero_imp.index = X_train.index\n",
    "        X_valid_zero_imp.index = X_valid.index\n",
    "        X_train_zero_imp = X_train_zero_imp.astype(float)\n",
    "        X_valid_zero_imp = X_valid_zero_imp.astype(float)\n",
    "        \n",
    "        # Mean imputation\n",
    "        # Reason:\n",
    "        mean_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        mean_features = ['host_acceptance_rate', 'review_scores_accuracy', 'review_scores_checkin', \n",
    "                         'review_scores_value', 'review_scores_location', 'review_scores_cleanliness', \n",
    "                         'review_scores_communication', 'review_scores_rating']\n",
    "        X_train_mean_imp = pd.DataFrame(mean_imp.fit_transform(X_train[mean_features]))\n",
    "        X_valid_mean_imp = pd.DataFrame(mean_imp.transform(X_valid[mean_features]))\n",
    "        X_train_mean_imp.columns = mean_features\n",
    "        X_valid_mean_imp.columns = mean_features\n",
    "        X_train_mean_imp.index = X_train.index\n",
    "        X_valid_mean_imp.index = X_valid.index\n",
    "        X_train_mean_imp = X_train_mean_imp.astype(float)\n",
    "        X_valid_mean_imp = X_valid_mean_imp.astype(float)\n",
    "        \n",
    "        # Mode imputation\n",
    "        # Reason: \n",
    "        mode_imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "        mode_features = ['bathrooms', 'bedrooms', 'beds', 'property_type']\n",
    "        X_train_mode_imp = pd.DataFrame(mode_imp.fit_transform(X_train[mode_features]))        \n",
    "        X_valid_mode_imp = pd.DataFrame(mode_imp.transform(X_valid[mode_features]))\n",
    "        X_train_mode_imp.columns = mode_features\n",
    "        X_valid_mode_imp.columns = mode_features\n",
    "        X_train_mode_imp.index = X_train.index\n",
    "        X_valid_mode_imp.index = X_valid.index\n",
    "        X_train_mode_imp[['bathrooms', 'bedrooms', 'beds']] = X_train_mode_imp[['bathrooms', 'bedrooms', 'beds']].astype(int)\n",
    "        X_valid_mode_imp[['bathrooms', 'bedrooms', 'beds']] = X_valid_mode_imp[['bathrooms', 'bedrooms', 'beds']].astype(int)\n",
    "        \n",
    "        # Replace the unimputated columns\n",
    "        for feature in zero_features:\n",
    "            X_train[feature] = X_train_zero_imp[feature]\n",
    "            X_valid[feature] = X_valid_zero_imp[feature]\n",
    "        \n",
    "        for feature in mean_features:\n",
    "            X_train[feature] = X_train_mean_imp[feature]\n",
    "            X_valid[feature] = X_valid_mean_imp[feature]\n",
    "\n",
    "        for feature in mode_features:\n",
    "            X_train[feature] = X_train_mode_imp[feature]\n",
    "            X_valid[feature] = X_valid_mode_imp[feature]\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "    \n",
    "    def _one_hot_encoding(self, X_train, X_valid, y_train, y_valid):\n",
    "        X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "        \n",
    "        oe_enc_features = ['cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', \n",
    "                               'neighbourhood_group_cleansed', 'property_type', 'instant_bookable', 'room_type', 'bed_type']\n",
    "        \n",
    "        oe = OrdinalEncoder()\n",
    "        X_train[oe_enc_features] = oe.fit_transform(X_train[oe_enc_features])\n",
    "        X_valid[oe_enc_features] = oe.transform(X_valid[oe_enc_features])\n",
    "    \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "    def _target_encoding(self, X_train, X_valid, y_train, y_valid):\n",
    "        X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "        \n",
    "        target_enc_features = ['cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', \n",
    "                               'neighbourhood_group_cleansed', 'property_type', 'instant_bookable', 'room_type', 'bed_type']\n",
    "        \n",
    "        # Create the encoder instance. Choose m to control noise.\n",
    "        target_enc = MEstimateEncoder(cols=target_enc_features, m=5.0)\n",
    "        X_train = target_enc.fit_transform(X_train, y_train)\n",
    "        X_valid = target_enc.transform(X_valid)\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "    \n",
    "    def getData(self, kfold, target_encoding=True):\n",
    "        data_frame = self.data_frame.copy()\n",
    "        \n",
    "        # Split train and valid\n",
    "        X_train = data_frame[data_frame.kfold != kfold]\n",
    "        X_valid = data_frame[data_frame.kfold == kfold]\n",
    "        y_train = X_train.pop('price')\n",
    "        y_valid = X_valid.pop('price')\n",
    "        \n",
    "        # Imputation\n",
    "        X_train, X_valid, y_train, y_valid = self._imputation(X_train, X_valid, y_train, y_valid)\n",
    "        \n",
    "        # Target Encoding\n",
    "        if target_encoding:\n",
    "            X_train, X_valid, y_train, y_valid = self._target_encoding(X_train, X_valid, y_train, y_valid)\n",
    "        else:\n",
    "            X_train, X_valid, y_train, y_valid = self._one_hot_encoding(X_train, X_valid, y_train, y_valid)\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580b0796-8ba7-49a0-8fab-b5524eafcb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sheet id and base url\n",
    "sheet_id = \"1M_qah-ym6O8vDcSmoKAP-lbZRPHUey83R_DJaW3LXfs\"\n",
    "base_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet=\"\n",
    "\n",
    "# Load metadata for three datasets\n",
    "listings_metadata = pd.read_csv(base_url+\"listings\")\n",
    "calendar_metadata = pd.read_csv(base_url+\"calendar\")\n",
    "reviews_metadata = pd.read_csv(base_url+\"reviews\")\n",
    "\n",
    "amenities = ['amenity_Washer', 'amenity_Air Conditioning', 'amenity_TV',\n",
    "             'amenity_Kitchen', 'amenity_Wheelchair Accessible',\n",
    "             'amenity_Free Parking on Premises', 'amenity_Doorman',\n",
    "             'amenity_Cable TV', 'amenity_Smoke Detector',\n",
    "             'amenity_Pets live on this property', 'amenity_Internet',\n",
    "             'amenity_Hangers', 'amenity_Family/Kid Friendly',\n",
    "             'amenity_First Aid Kit', 'amenity_Indoor Fireplace', 'amenity_Gym',\n",
    "             'amenity_Suitable for Events', 'amenity_Breakfast', 'amenity_Cat(s)',\n",
    "             'amenity_Lock on Bedroom Door', 'amenity_Smoking Allowed',\n",
    "             'amenity_Dog(s)', 'amenity_Shampoo', 'amenity_Hair Dryer',\n",
    "             'amenity_Carbon Monoxide Detector', 'amenity_Wireless Internet',\n",
    "             'amenity_Hot Tub', 'amenity_Safety Card',\n",
    "             'amenity_Buzzer/Wireless Intercom', 'amenity_Pool',\n",
    "             'amenity_Elevator in Building', 'amenity_Pets Allowed',\n",
    "             'amenity_Fire Extinguisher', 'amenity_Other pet(s)',\n",
    "             'amenity_Laptop Friendly Workspace', 'amenity_Essentials',\n",
    "             'amenity_Iron', 'amenity_Dryer', 'amenity_24-Hour Check-in',\n",
    "             'amenity_Heating']\n",
    "    \n",
    "# ML1 + ML2\n",
    "ml1 = listings_metadata[listings_metadata.ML == 1].Label.to_list()\n",
    "useless_features = ['availability_30', 'availability_60', 'availability_90', 'availability_365', 'first_review', 'last_review', 'amenities']\n",
    "for useless_feature in useless_features:\n",
    "    ml1.remove(useless_feature)\n",
    "ml2 = listings_metadata[listings_metadata.ML == 2].Label.to_list()\n",
    "ml2.append('demand')\n",
    "ml2 = ml1 + ml2 + amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8bba2-5fea-411c-a1b5-582918f07f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d86b6121-a9c0-4a22-9421-7b4ad487daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence Optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe0d8c-7c19-40ea-94be-7394e777a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Define logger\n",
    "logger = logging.getLogger('ML')\n",
    "\n",
    "# Set level for logger\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Define the handler and formatter for console logging\n",
    "consoleHandler = logging.StreamHandler() # Define StreamHandler\n",
    "consoleHandler.setLevel(logging.DEBUG) # Set level\n",
    "concolsFormatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s') # Define formatter\n",
    "consoleHandler.setFormatter(concolsFormatter) # Set formatter\n",
    "logger.addHandler(consoleHandler) # Add handler to logger\n",
    "\n",
    "# Define the handler and formatter for file logging\n",
    "log_file = 'ML'\n",
    "fileHandler = logging.FileHandler(f'{log_file}.log') # Define FileHandler\n",
    "fileHandler.setLevel(logging.INFO) # Set level\n",
    "fileFormatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') # Define formatter\n",
    "fileHandler.setFormatter(fileFormatter) # Set formatter\n",
    "logger.addHandler(fileHandler) # Add handler to logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789bc952-a9e6-4807-81f7-f9303b86ceb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118db56-0c18-41cf-9bf5-a37ae38ba0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50785d-5a14-4cbb-b3fe-d5f1f0f26843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f6d1c-9c3c-40d2-b03d-abe06a521553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8daccc6-5598-4e9f-b637-1eb121f0f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Modeling tuning with Target encoding.\n",
    "    \"\"\"\n",
    "    features = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "                'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "                'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "                'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "                'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "                'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "                'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "    ml_pipeline = ML_pipeline(data_frame=listings, features=features, target='price')\n",
    "    \n",
    "    RMSE_AVG = []\n",
    "    for kfold in range(5):\n",
    "        X_train, X_valid, y_train, y_valid = ml_pipeline.getData(kfold=kfold, target_encoding=True)\n",
    "        X_train, X_valid = X_train[ml2], X_valid[ml2]\n",
    "        \n",
    "        # Hyperparameters for XGBoost\n",
    "        xgb_params = {\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0),\n",
    "            'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0),\n",
    "            'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "            'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.3, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 10000),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 1, 7),\n",
    "            'random_state': trial.suggest_categorical('random_state', [0, 42, 2021]),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300)\n",
    "        }\n",
    "\n",
    "        model = XGBRegressor(\n",
    "                tree_method='gpu_hist',\n",
    "                gpu_id=0,\n",
    "                predictor='gpu_predictor',\n",
    "                **xgb_params)\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train, \n",
    "            early_stopping_rounds=300,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            verbose=5000\n",
    "        )\n",
    "        \n",
    "        valid_preds = model.predict(X_valid)\n",
    "        RMSE = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        RMSE_AVG.append(RMSE)\n",
    "    \n",
    "    return np.mean(RMSE_AVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5c385cb-5812-46ab-9302-d6c8137e9250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:147.94261\n",
      "[1945]\tvalidation_0-rmse:52.52376\n",
      "[0]\tvalidation_0-rmse:155.57033\n",
      "[1551]\tvalidation_0-rmse:63.43641\n",
      "[0]\tvalidation_0-rmse:143.89220\n",
      "[1018]\tvalidation_0-rmse:60.78948\n",
      "[0]\tvalidation_0-rmse:150.55839\n",
      "[1957]\tvalidation_0-rmse:60.30193\n",
      "[0]\tvalidation_0-rmse:149.22893\n",
      "[1070]\tvalidation_0-rmse:52.06042\n",
      "[0]\tvalidation_0-rmse:123.03511\n",
      "[236]\tvalidation_0-rmse:53.15327\n",
      "[0]\tvalidation_0-rmse:130.36479\n",
      "[236]\tvalidation_0-rmse:62.76877\n",
      "[0]\tvalidation_0-rmse:119.33671\n",
      "[236]\tvalidation_0-rmse:61.32449\n",
      "[0]\tvalidation_0-rmse:127.00924\n",
      "[236]\tvalidation_0-rmse:60.25604\n",
      "[0]\tvalidation_0-rmse:122.62102\n",
      "[236]\tvalidation_0-rmse:53.49147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ML - INFO - Study name: XGBoost 2 trails\n",
      "ML - INFO - Best value: 57.569528148901256\n",
      "ML - INFO - Best paras: {'lambda': 8.421397225788358, 'alpha': 1.7746425844002305, 'reg_lambda': 8.849439210374493e-08, 'reg_alpha': 91.07013803579041, 'colsample_bytree': 0.7966894331786722, 'subsample': 0.5288987673006816, 'learning_rate': 0.25643891041241484, 'n_estimators': 237, 'max_depth': 7, 'random_state': 2021, 'min_child_weight': 165}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 58s, sys: 10.5 s, total: 5min 9s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_trials = 200\n",
    "study = optuna.create_study(direction='minimize', study_name=f'XGBoost {n_trials} trails')\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False) # set n_triasl\n",
    "\n",
    "logger.info(f\"Study name: {study.study_name}\")\n",
    "logger.info(f\"Best value: {study.best_value}\")\n",
    "logger.info(f\"Best paras: {study.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "557971e1-17b4-40a7-9056-4b13b5acc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Modeling tuning with Target encoding.\n",
    "    \"\"\"\n",
    "    features = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "                'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "                'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "                'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "                'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "                'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "                'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "    ml_pipeline = ML_pipeline(data_frame=listings, features=features, target='price')\n",
    "    \n",
    "    RMSE_AVG = []\n",
    "    for kfold in range(5):\n",
    "        X_train, X_valid, y_train, y_valid = ml_pipeline.getData(kfold=kfold, target_encoding=True)\n",
    "        X_train, X_valid = X_train[ml2], X_valid[ml2]\n",
    "        \n",
    "        # Hyperparameters for LightGBM\n",
    "        lgb_params = {\n",
    "            'random_state': trial.suggest_categorical('random_state', [0, 42, 2021]),\n",
    "            'num_iterations': trial.suggest_int('num_iterations', 100, 10000),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 7),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 100, 2000),\n",
    "            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.01, 0.99),\n",
    "            'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.01, 0.99),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        }\n",
    "\n",
    "        model = LGBMRegressor(\n",
    "                    device='gpu',\n",
    "                    gpu_platform_id=0,\n",
    "                    gpu_device_id=0,\n",
    "                    n_jobs=-1,\n",
    "                    metric='rmse',\n",
    "                    **lgb_params\n",
    "        )\n",
    "        \n",
    "        #model.fit(X_train[ml2]\\, y_train)\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train, \n",
    "            early_stopping_rounds=300,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            verbose=5000\n",
    "        )\n",
    "        \n",
    "        valid_preds = model.predict(X_valid)\n",
    "        RMSE = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        RMSE_AVG.append(RMSE)\n",
    "    \n",
    "    return np.mean(RMSE_AVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37cc0b-e51a-4187-9ade-91130d9143a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_trials = 200\n",
    "study = optuna.create_study(direction='minimize', study_name=f'LGBoost {n_trials} trails')\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False) # set n_triasl\n",
    "\n",
    "logger.info(f\"Study name: {study.study_name}\")\n",
    "logger.info(f\"Best value: {study.best_value}\")\n",
    "logger.info(f\"Best paras: {study.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffbdf5e3-19f8-453e-b185-9e31090d24c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8680ff96-7e34-4dd9-9681-bd9852316123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f9fe43-6afd-4469-b0aa-4b9bdf902b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b480efd2-8ace-4e98-85b8-15d1ebaeadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmail_user = 'zacks.shen.dev@gmail.com'\n",
    "gmail_password = 'lunbtmvtoiovzvhy' # Google App Password\n",
    "\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "msg = EmailMessage()\n",
    "msg[\"From\"] = 'zacks.shen.dev@gmail.com'\n",
    "msg[\"Subject\"] = \"Seattle Airbnb ML Tuning\"\n",
    "msg[\"To\"] = ['zacks.shen@gmail.com']\n",
    "msg.set_content(\"Mission Complete!\")\n",
    "with open('ML.log', 'rb') as f:\n",
    "    content = f.read()\n",
    "    msg.add_attachment(content, maintype='application', subtype='log', filename='ML.log')\n",
    "\n",
    "server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "server.login(gmail_user, gmail_password)\n",
    "server.send_message(msg)\n",
    "server.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652c689-f18e-4f63-a0d7-5932b7c29d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
